{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "file_path = Path(\"data/marked_sentences_472_cutted.csv\")\n",
    "\n",
    "try:\n",
    "\n",
    "    slavery = pd.read_csv(file_path, encoding='utf-8')\n",
    "except pd.errors.ParserError:\n",
    "    try:\n",
    "    \n",
    "        slavery = pd.read_csv(file_path, encoding='utf-8', sep=';')\n",
    "    except pd.errors.ParserError:\n",
    "    \n",
    "        slavery = pd.read_csv(file_path, encoding='utf-8', header=None)\n",
    "\n",
    "slavery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad1cda",
   "metadata": {},
   "source": [
    "Или:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1349743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "file_path = Path(\"data/unmarked_sentences_cutted.csv\")\n",
    "\n",
    "try:\n",
    "\n",
    "    all_cases = pd.read_csv(file_path, encoding='utf-8')\n",
    "except pd.errors.ParserError:\n",
    "    try:\n",
    "    \n",
    "        all_cases = pd.read_csv(file_path, encoding='utf-8', sep=';')\n",
    "    except pd.errors.ParserError:\n",
    "    \n",
    "        all_cases = pd.read_csv(file_path, encoding='utf-8', header=None)\n",
    "\n",
    "all_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "genai.configure(api_key=\"ВАШ_АПИ_КЛЮЧ\")\n",
    "\n",
    "# Функция для оценки количества токенов\n",
    "def estimate_tokens(text):\n",
    "    return math.ceil(len(text) / 3)  # Оценка: 1 токен ≈ 3 символа\n",
    "\n",
    "# Функция для обработки батча\n",
    "def classify_batch(batch):\n",
    "    try:\n",
    "        prompt = \"\"\"ТЕКСТ ИНСТРУКЦИИ\n",
    "        Проанализируй следующие приговоры и верни JSON в формате:\n",
    "        [\n",
    "            {{\"case_number\": \"<номер дела>\", \"slavery_detected\": true/false, \"reason\": \"<обоснование>\", \"victim\": <количество жертв (если есть, иначе 0)>}},\n",
    "            ...\n",
    "        ]\n",
    "\n",
    "        **Приговоры**:\n",
    "        \"\"\"\n",
    "\n",
    "        for case_number, text in batch:\n",
    "            prompt += f\"\\n\\nНомер дела: {case_number}\\nТекст: {text}\\n---\"\n",
    "\n",
    "        model = genai.GenerativeModel(\"gemini-2.5-pro-exp-03-25\")\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        response_text = response.text.strip()\n",
    "        print(f\"Ответ модели:\\n{response_text}\")\n",
    "\n",
    "        return safe_json_parse(response_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обработки batch {batch}: {e}\")\n",
    "        return [{\"case_number\": case_number, \"slavery_detected\": None, \"reason\": \"Ошибка обработки\", \"victim\": 0} for case_number, _ in batch]\n",
    "\n",
    "# Функция для парсинга JSON\n",
    "def safe_json_parse(response_text):\n",
    "    try:\n",
    "        response_text = response_text.strip(\"```json\").strip(\"```\").strip()\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Ошибка декодирования JSON: {response_text}\")\n",
    "        return []\n",
    "\n",
    "if \"slavery\" not in locals():\n",
    "    raise ValueError(\"slavery не определен!\")\n",
    "\n",
    "slavery = slavery.drop_duplicates()\n",
    "\n",
    "if \"text\" not in slavery.columns:\n",
    "    raise ValueError(\"Файл не содержит колонку 'text'!\")\n",
    "\n",
    "# Оцениваем количество токенов в каждом приговоре\n",
    "slavery[\"num_tokens\"] = slavery[\"text\"].apply(estimate_tokens)\n",
    "\n",
    "# Разбиваем приговоры на батчи по ≤ 200K токенов\n",
    "batch = []\n",
    "current_tokens = 0\n",
    "batches = []\n",
    "\n",
    "for _, row in slavery.iterrows():\n",
    "    case_number, text, tokens = row[\"case_number\"], row[\"text\"], row[\"num_tokens\"]\n",
    "    \n",
    "    if current_tokens + tokens > 195000:\n",
    "        batches.append(batch)\n",
    "        batch = []\n",
    "        current_tokens = 0\n",
    "    \n",
    "    batch.append((case_number, text))\n",
    "    current_tokens += tokens\n",
    "\n",
    "if batch:\n",
    "    batches.append(batch)\n",
    "\n",
    "results = []\n",
    "for batch in batches:\n",
    "    batch_results = classify_batch(batch)\n",
    "    results.extend(batch_results)\n",
    "\n",
    "    print(\"Ожидание 10 секунд перед следующим запросом...\")\n",
    "    time.sleep(10)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"тест1.csv\", index=False)\n",
    "\n",
    "print(\"Классификация завершена! Результат сохранен в 'тест1.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d02d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = Path(\"data/gemini25_version3.csv\")\n",
    "\n",
    "try:\n",
    "\n",
    "    slavery_classified = pd.read_csv(file_path, encoding='utf-8')\n",
    "except pd.errors.ParserError:\n",
    "    try:\n",
    "    \n",
    "        slavery_classified = pd.read_csv(file_path, encoding='utf-8', sep=';')\n",
    "    except pd.errors.ParserError:\n",
    "    \n",
    "        slavery_classified = pd.read_csv(file_path, encoding='utf-8', header=None)\n",
    "\n",
    "slavery_classified.rename(columns={'text_x': 'text'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выполнение этой ячейки необходимо, если результат классификации ИИ не был предварительно соединен с размеченным датафреймом\n",
    "df_merged = slavery.merge(slavery_classified, on=['case_number'], how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac67e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df_merged['slavery_detected'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "non_na_rows = df_merged[df_merged['slavery_detected'].notna()]\n",
    "len(non_na_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.dropna(subset=['slavery_detected'])\n",
    "df_merged['slavery_detected'] = df_merged['slavery_detected'].map({True: 1, False: 0})\n",
    "#slavery['slavery_detected'] = slavery['slavery_detected'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "y_true = df_merged['Slavery_1_step']  # Ручная разметка\n",
    "y_pred = df_merged['slavery_detected']  # Разметка ИИ\n",
    "\n",
    "# Рассчитываем ROC AUC\n",
    "roc_auc = roc_auc_score(y_true, y_pred)\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Выводим Classification Report для классификации 1\n",
    "print(\"\\nClassification Report - slav_1:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Рассчитываем взвешенную F1-меру вручную\n",
    "weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f\"\\nWeighted F1 Score: {weighted_f1:.4f}\")\n",
    "\n",
    "# Рассчитываем macro-average F1-меру вручную\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"\\nMacro-average F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "# Выводим матрицу ошибок для slav_1\n",
    "cm_1 = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nConfusion Matrix - slav_2:\")\n",
    "print(cm_1)\n",
    "\n",
    "# Визуализируем матрицу ошибок\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "sns.heatmap(cm_1, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'], ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - slav_2')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
